{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68299b32-4824-41c6-8de6-73c3e1133865",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sidde\\AppData\\Local\\Temp\\ipykernel_8760\\1334356797.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat(df_list, ignore_index=True)\n",
      "C:\\Users\\sidde\\AppData\\Local\\Temp\\ipykernel_8760\\1334356797.py:42: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  full_data[col] = full_data[col].astype(str).str.strip().str.lower().replace({'true': True, 'false': False})\n",
      "C:\\Users\\sidde\\AppData\\Local\\Temp\\ipykernel_8760\\1334356797.py:42: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  full_data[col] = full_data[col].astype(str).str.strip().str.lower().replace({'true': True, 'false': False})\n",
      "C:\\Users\\sidde\\AppData\\Local\\Temp\\ipykernel_8760\\1334356797.py:42: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  full_data[col] = full_data[col].astype(str).str.strip().str.lower().replace({'true': True, 'false': False})\n",
      "C:\\Users\\sidde\\AppData\\Local\\Temp\\ipykernel_8760\\1334356797.py:42: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  full_data[col] = full_data[col].astype(str).str.strip().str.lower().replace({'true': True, 'false': False})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database 'bird_observations.db' created successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# === 1. File paths ===\n",
    "forest_file = \"C:/Users/sidde/Downloads/Bird_Monitoring_Data_FOREST.XLSX\"\n",
    "grassland_file = \"C:/Users/sidde/Downloads/Bird_Monitoring_Data_GRASSLAND.XLSX\"\n",
    "\n",
    "# === 2. Load sheet names ===\n",
    "forest_sheets = pd.ExcelFile(forest_file).sheet_names\n",
    "grassland_sheets = pd.ExcelFile(grassland_file).sheet_names\n",
    "\n",
    "# === 3. Load & label each sheet ===\n",
    "def load_and_label_sheets(file_path, sheet_names, location_type):\n",
    "    df_list = []\n",
    "    for sheet in sheet_names:\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet)\n",
    "        df['Admin_Unit_Code'] = sheet\n",
    "        df['Location_Type'] = location_type\n",
    "        df_list.append(df)\n",
    "    return pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "forest_data = load_and_label_sheets(forest_file, forest_sheets, \"Forest\")\n",
    "grassland_data = load_and_label_sheets(grassland_file, grassland_sheets, \"Grassland\")\n",
    "\n",
    "# === 4. Merge datasets ===\n",
    "full_data = pd.concat([forest_data, grassland_data], ignore_index=True)\n",
    "\n",
    "# === 5. Clean columns ===\n",
    "full_data['Date'] = pd.to_datetime(full_data['Date'], errors='coerce')\n",
    "full_data['Start_Time'] = pd.to_datetime(full_data['Start_Time'], errors='coerce').dt.time\n",
    "full_data['End_Time'] = pd.to_datetime(full_data['End_Time'], errors='coerce').dt.time\n",
    "full_data['Temperature'] = pd.to_numeric(full_data['Temperature'], errors='coerce')\n",
    "full_data['Humidity'] = pd.to_numeric(full_data['Humidity'], errors='coerce')\n",
    "full_data['Visit'] = pd.to_numeric(full_data['Visit'], errors='coerce')\n",
    "\n",
    "# Boolean-like columns\n",
    "bool_columns = [\n",
    "    'Flyover_Observed', 'PIF_Watchlist_Status', 'Regional_Stewardship_Status',\n",
    "    'Initial_Three_Min_Cnt'\n",
    "]\n",
    "for col in bool_columns:\n",
    "    full_data[col] = full_data[col].astype(str).str.strip().str.lower().replace({'true': True, 'false': False})\n",
    "    full_data[col] = full_data[col].astype('boolean')\n",
    "\n",
    "# === 6. Save to SQLite ===\n",
    "conn = sqlite3.connect(\"bird_observations.db\")\n",
    "full_data.to_sql(\"bird_data\", conn, if_exists=\"replace\", index=False)\n",
    "conn.close()\n",
    "\n",
    "print(\"Database 'bird_observations.db' created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba28e2b3-a83a-49b6-8ef9-e81d28c73635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Exported: exports\\total_unique_species.csv\n",
      " Exported: exports\\total_observations.csv\n",
      " Exported: exports\\species_count_per_habitat.csv\n",
      " Exported: exports\\top10_species_overall.csv\n",
      " Exported: exports\\top10_species_per_habitat.csv\n",
      " Exported: exports\\monthly_observation_trend.csv\n",
      " Exported: exports\\yearly_observation_trend.csv\n",
      " Exported: exports\\seasonal_patterns.csv\n",
      " Exported: exports\\time_of_day_pattern.csv\n",
      " Exported: exports\\threatened_species_per_habitat.csv\n",
      " Exported: exports\\regional_stewardship_species_per_habitat.csv\n",
      " Exported: exports\\temperature_vs_species_richness.csv\n",
      " Exported: exports\\humidity_vs_species_richness.csv\n",
      " Exported: exports\\top_observers.csv\n",
      " Exported Shannon Index: exports\\species_diversity_per_admin.csv\n",
      "\n",
      "All queries executed and exported successfully!\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# === 1. Setup ===\n",
    "db_path = \"bird_observations.db\"\n",
    "export_folder = \"exports\"\n",
    "\n",
    "# Create folder if not exists\n",
    "os.makedirs(export_folder, exist_ok=True)\n",
    "\n",
    "# Connect to database\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# === 2. Queries dictionary (without LOG in Shannon Index) ===\n",
    "queries = {\n",
    "    # Habitat & Species Overview\n",
    "    \"total_unique_species\": \"\"\"\n",
    "        SELECT COUNT(DISTINCT TaxonCode) AS unique_species\n",
    "        FROM bird_data\n",
    "        WHERE TaxonCode IS NOT NULL\n",
    "    \"\"\",\n",
    "    \"total_observations\": \"\"\"\n",
    "        SELECT COUNT(*) AS total_observations\n",
    "        FROM bird_data\n",
    "    \"\"\",\n",
    "    \"species_count_per_habitat\": \"\"\"\n",
    "        SELECT Location_Type, COUNT(DISTINCT TaxonCode) AS species_count\n",
    "        FROM bird_data\n",
    "        GROUP BY Location_Type\n",
    "    \"\"\",\n",
    "\n",
    "    # Species Rankings\n",
    "    \"top10_species_overall\": \"\"\"\n",
    "        SELECT TaxonCode, COUNT(*) AS observations\n",
    "        FROM bird_data\n",
    "        WHERE TaxonCode IS NOT NULL\n",
    "        GROUP BY TaxonCode\n",
    "        ORDER BY observations DESC\n",
    "        LIMIT 10\n",
    "    \"\"\",\n",
    "    \"top10_species_per_habitat\": \"\"\"\n",
    "        SELECT Location_Type, TaxonCode, COUNT(*) AS observations\n",
    "        FROM bird_data\n",
    "        WHERE TaxonCode IS NOT NULL\n",
    "        GROUP BY Location_Type, TaxonCode\n",
    "        ORDER BY Location_Type, observations DESC\n",
    "    \"\"\",\n",
    "\n",
    "    # Time & Trend Analysis\n",
    "    \"monthly_observation_trend\": \"\"\"\n",
    "        SELECT STRFTIME('%m', Date) AS month, COUNT(*) AS observations\n",
    "        FROM bird_data\n",
    "        WHERE Date IS NOT NULL\n",
    "        GROUP BY month\n",
    "        ORDER BY month\n",
    "    \"\"\",\n",
    "    \"yearly_observation_trend\": \"\"\"\n",
    "        SELECT STRFTIME('%Y', Date) AS year, COUNT(*) AS observations\n",
    "        FROM bird_data\n",
    "        WHERE year IS NOT NULL\n",
    "        GROUP BY year\n",
    "        ORDER BY year\n",
    "    \"\"\",\n",
    "    \"seasonal_patterns\": \"\"\"\n",
    "        SELECT CASE\n",
    "            WHEN STRFTIME('%m', Date) IN ('12','01','02') THEN 'Winter'\n",
    "            WHEN STRFTIME('%m', Date) IN ('03','04','05') THEN 'Spring'\n",
    "            WHEN STRFTIME('%m', Date) IN ('06','07','08') THEN 'Summer'\n",
    "            WHEN STRFTIME('%m', Date) IN ('09','10','11') THEN 'Autumn'\n",
    "        END AS season,\n",
    "        COUNT(*) AS observations\n",
    "        FROM bird_data\n",
    "        WHERE Date IS NOT NULL\n",
    "        GROUP BY season\n",
    "    \"\"\",\n",
    "    \"time_of_day_pattern\": \"\"\"\n",
    "        SELECT CASE\n",
    "            WHEN CAST(STRFTIME('%H', Start_Time) AS INTEGER) BETWEEN 5 AND 11 THEN 'Morning'\n",
    "            WHEN CAST(STRFTIME('%H', Start_Time) AS INTEGER) BETWEEN 12 AND 16 THEN 'Afternoon'\n",
    "            WHEN CAST(STRFTIME('%H', Start_Time) AS INTEGER) BETWEEN 17 AND 20 THEN 'Evening'\n",
    "            ELSE 'Night'\n",
    "        END AS time_of_day,\n",
    "        COUNT(*) AS observations\n",
    "        FROM bird_data\n",
    "        WHERE Start_Time IS NOT NULL\n",
    "        GROUP BY time_of_day\n",
    "    \"\"\",\n",
    "\n",
    "    # Threat Status & Conservation\n",
    "    \"threatened_species_per_habitat\": \"\"\"\n",
    "        SELECT Location_Type, COUNT(DISTINCT TaxonCode) AS threatened_species\n",
    "        FROM bird_data\n",
    "        WHERE PIF_Watchlist_Status = 1\n",
    "        GROUP BY Location_Type\n",
    "    \"\"\",\n",
    "    \"regional_stewardship_species_per_habitat\": \"\"\"\n",
    "        SELECT Location_Type, COUNT(DISTINCT TaxonCode) AS stewardship_species\n",
    "        FROM bird_data\n",
    "        WHERE Regional_Stewardship_Status = 1\n",
    "        GROUP BY Location_Type\n",
    "    \"\"\",\n",
    "\n",
    "    # Environmental Factors\n",
    "    \"temperature_vs_species_richness\": \"\"\"\n",
    "        SELECT ROUND(Temperature, 0) AS temp_rounded, COUNT(DISTINCT TaxonCode) AS species_richness\n",
    "        FROM bird_data\n",
    "        WHERE Temperature IS NOT NULL\n",
    "        GROUP BY temp_rounded\n",
    "        ORDER BY temp_rounded\n",
    "    \"\"\",\n",
    "    \"humidity_vs_species_richness\": \"\"\"\n",
    "        SELECT ROUND(Humidity, 0) AS humidity_rounded, COUNT(DISTINCT TaxonCode) AS species_richness\n",
    "        FROM bird_data\n",
    "        WHERE Humidity IS NOT NULL\n",
    "        GROUP BY humidity_rounded\n",
    "        ORDER BY humidity_rounded\n",
    "    \"\"\",\n",
    "\n",
    "    # Observer & Location Analysis — Step 1 only (counts)\n",
    "    \"species_diversity_per_admin\": \"\"\"\n",
    "        SELECT Admin_Unit_Code, TaxonCode, COUNT(*) AS species_count\n",
    "        FROM bird_data\n",
    "        WHERE TaxonCode IS NOT NULL\n",
    "        GROUP BY Admin_Unit_Code, TaxonCode\n",
    "    \"\"\",\n",
    "    \"top_observers\": \"\"\"\n",
    "        SELECT Observer, COUNT(*) AS total_observations\n",
    "        FROM bird_data\n",
    "        WHERE Observer IS NOT NULL\n",
    "        GROUP BY Observer\n",
    "        ORDER BY total_observations DESC\n",
    "        LIMIT 10\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "# === 3. Run all queries except Shannon Index ===\n",
    "for name, query in queries.items():\n",
    "    if name != \"species_diversity_per_admin\":\n",
    "        df = pd.read_sql_query(query, conn)\n",
    "        csv_path = os.path.join(export_folder, f\"{name}.csv\")\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        print(f\" Exported: {csv_path}\")\n",
    "\n",
    "# === 4. Calculate Shannon Index in Python ===\n",
    "df_diversity = pd.read_sql_query(queries[\"species_diversity_per_admin\"], conn)\n",
    "diversity_results = []\n",
    "for admin_unit, group in df_diversity.groupby(\"Admin_Unit_Code\"):\n",
    "    total_count = group[\"species_count\"].sum()\n",
    "    proportions = group[\"species_count\"] / total_count\n",
    "    shannon_index = -np.sum(proportions * np.log(proportions))\n",
    "    diversity_results.append({\n",
    "        \"Admin_Unit_Code\": admin_unit,\n",
    "        \"species_count\": group[\"species_count\"].nunique(),\n",
    "        \"shannon_index\": round(shannon_index, 3)\n",
    "    })\n",
    "\n",
    "df_shannon = pd.DataFrame(diversity_results)\n",
    "csv_path = os.path.join(export_folder, \"species_diversity_per_admin.csv\")\n",
    "df_shannon.to_csv(csv_path, index=False)\n",
    "print(f\" Exported Shannon Index: {csv_path}\")\n",
    "\n",
    "# === 5. Close connection ===\n",
    "conn.close()\n",
    "print(\"\\nAll queries executed and exported successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6074ae4-f99f-417d-989f-2c3953f42164",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
